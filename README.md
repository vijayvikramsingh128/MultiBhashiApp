# MultiBhashiApp
Using Retrofit library with Gson
"Learn" type has been shown in orange colour.
"Question" type has been shown in green colour.
"concept name" and "pronunciation" also has been displayed at slide as it is in API
i have used sliding at the place of next button for next sliding to next fragment.
audio in the next slide is pre-fetched
The sequence of slides  depends on the data in the API
For audio matching feature, the user receives a feedback. (e.g.  98 % matched)
For comparing text Levenshtein distance algorithm has been used
UI architecture have not been used to implement  task using(MVP, MVVM...) as i am new to this.
After comparing text ,a toast message with matched percentage has been displayed
For playing media ,"Mediaplayer" Class in android API has been used 
For speech to text converting ,"SpeechRecogniser" Class android API has been used
